{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sondDJpRRvXI"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTo12aZ4Ryrr",
        "outputId": "bd83633b-84d7-4f13-d285-dc803c97c7b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-02-24 09:30:34--  https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 272637746 (260M) [application/x-gzip]\n",
            "Saving to: â€˜spark-3.2.1-bin-hadoop2.7.tgzâ€™\n",
            "\n",
            "spark-3.2.1-bin-had 100%[===================>] 260.01M   213MB/s    in 1.2s    \n",
            "\n",
            "2022-02-24 09:30:47 (213 MB/s) - â€˜spark-3.2.1-bin-hadoop2.7.tgzâ€™ saved [272637746/272637746]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget  https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFpzrho6R-fX"
      },
      "outputs": [],
      "source": [
        "!tar xf spark-3.2.1-bin-hadoop2.7.tgz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucqWbWzTSAd6"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbWynPx2U2gj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dB5ZuR2U9JL"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptck-WabU_1P"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvUpHu-LVGAs",
        "outputId": "7289eb23-d0bc-4865-d7e5-23be001dc963"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import udf, lit, when, date_sub\n",
        "from pyspark.sql.types import ArrayType, IntegerType, StructType, StructField, StringType\n",
        "from pyspark.sql.types import BooleanType, DateType, DoubleType\n",
        "import json\n",
        "from pyspark import SparkContext, SparkConf, SQLContext\n",
        "from pyspark.sql import Row\n",
        "from datetime import datetime\n",
        "\n",
        "# conf = SparkConf().setAppName('Colab').setMaster('local')\n",
        "# sc = SparkContext(conf=spark)\n",
        "sqlContext = SQLContext(spark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "q9BCo-14EwQR",
        "outputId": "8ff85b42-7ced-4fe6-e285-d08202a471d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://68c043300693:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local appName=Colab>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glcVJQP0VXZT",
        "outputId": "7d37ac62-db0c-4193-da9d-a698890f0024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------------+----------+---------------------------------+--------------------+\n",
            "| id|            attr|start_date|events_data_timestamp_unixtime_ms|dataFields_createdAt|\n",
            "+---+----------------+----------+---------------------------------+--------------------+\n",
            "|  1|          Hello!|1643937003|                    1643825926704|2022-02-02 18:18:...|\n",
            "|  4|    Hello World!|1643937003|                    1643825926704|2022-02-02 18:18:...|\n",
            "|  2|    Hello Spark!|1644122255|                              NaN|2022-02-02 18:18:...|\n",
            "|  3|Hello Old World!|1643991898|                    1643825926704|2022-02-02 18:18:...|\n",
            "|  5|    Hello Spark!|       NaN|                              NaN|2022-02-02 18:18:...|\n",
            "+---+----------------+----------+---------------------------------+--------------------+\n",
            "\n",
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- attr: string (nullable = true)\n",
            " |-- start_date: string (nullable = true)\n",
            " |-- events_data_timestamp_unixtime_ms: string (nullable = true)\n",
            " |-- dataFields_createdAt: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# existing data set\n",
        "import math\n",
        "\n",
        "test_df = [\n",
        "Row(1, \"Hello!\", 1643937003, '1643825926704', '2022-02-02 18:18:46 +00:00'),\n",
        "Row(4, \"Hello World!\", 1643937003, '1643825926704', '2022-02-02 18:18:46 +00:00'),\n",
        "Row(2, \"Hello Spark!\", 1644122255, math.nan, '2022-02-02 18:18:46 +00:00'),\n",
        "Row(3, \"Hello Old World!\", 1643991898, '1643825926704', '2022-02-02 18:18:46 +00:00'),\n",
        "Row(5, \"Hello Spark!\", math.nan, math.nan, '2022-02-02 18:18:46 +00:00')\n",
        "]\n",
        "schema_target = StructType([\n",
        "StructField(\"id\", IntegerType(), True),\n",
        "StructField(\"attr\", StringType(), True),\n",
        "StructField(\"start_date\", StringType(), True),\n",
        "StructField(\"events_data_timestamp_unixtime_ms\", StringType(), True),\n",
        "StructField(\"dataFields_createdAt\", StringType(), True)\n",
        "])\n",
        "test_df = sqlContext.createDataFrame(\n",
        "spark.sparkContext.parallelize(test_df),\n",
        "schema_target\n",
        ")\n",
        "test_df.show()\n",
        "# df_target = df_target.withColumn(\"start_date\", lit(df_target[\"start_date\"]/1000))\n",
        "# df_target = df_target.withColumn(\"start_date\", df_target[\"start_date\"].cast(StringType()))\n",
        "test_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3pSCsHXjnkD",
        "outputId": "8d265722-9b5d-41b2-bdb0-4ace747c837f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------------+----------+---------------------------------+--------------------+-----------+------------------------------------------+-----------------------------------------------+------------------------------------------+-----------------------------------------------+\n",
            "| id|            attr|start_date|events_data_timestamp_unixtime_ms|dataFields_createdAt|report_date|events_data_timestamp_unixtime_ms_pst_calc|events_data_timestamp_unixtime_ms_pst_date_calc|events_data_timestamp_unixtime_ms_utc_calc|events_data_timestamp_unixtime_ms_utc_date_calc|\n",
            "+---+----------------+----------+---------------------------------+--------------------+-----------+------------------------------------------+-----------------------------------------------+------------------------------------------+-----------------------------------------------+\n",
            "|  1|          Hello!|1643937003|                    1643825926704|2022-02-02 18:18:...| 03/02/2022|                       2022-02-03 17:10:03|                            2022-02-03 16:00:00|                       2022-02-04 01:10:03|                            2022-02-04 00:00:00|\n",
            "|  4|    Hello World!|1643937003|                    1643825926704|2022-02-02 18:18:...| 03/02/2022|                       2022-02-03 17:10:03|                            2022-02-03 16:00:00|                       2022-02-04 01:10:03|                            2022-02-04 00:00:00|\n",
            "|  2|    Hello Spark!|1644122255|                              NaN|2022-02-02 18:18:...| 05/02/2022|                       2022-02-05 20:37:35|                            2022-02-05 16:00:00|                       2022-02-06 04:37:35|                            2022-02-06 00:00:00|\n",
            "|  3|Hello Old World!|1643991898|                    1643825926704|2022-02-02 18:18:...| 04/02/2022|                       2022-02-04 08:24:58|                            2022-02-03 16:00:00|                       2022-02-04 16:24:58|                            2022-02-04 00:00:00|\n",
            "|  5|    Hello Spark!|       NaN|                              NaN|2022-02-02 18:18:...|       null|                                      null|                                           null|                                      null|                                           null|\n",
            "+---+----------------+----------+---------------------------------+--------------------+-----------+------------------------------------------+-----------------------------------------------+------------------------------------------+-----------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import unix_timestamp\n",
        "from pyspark.sql import functions as f\n",
        "\n",
        "# df_target = test_df.withColumn(\"report_date\", f.from_unixtime(\"start_date\", \"yyyy-MM-dd HH:mm:ss\"))\n",
        "test_df = test_df.withColumn(\"report_date\", f.date_format(f.from_utc_timestamp(f.from_unixtime(\"start_date\", \"yyyy-MM-dd HH:mm:ss\"), \"America/Los_Angeles\"), \"dd/MM/yyyy\"))\n",
        "test_df = test_df.withColumn(\"events_data_timestamp_unixtime_ms_pst_calc\", f.from_utc_timestamp(f.from_unixtime(\"start_date\", \"yyyy-MM-dd HH:mm:ss\"), \"America/Los_Angeles\"))\n",
        "test_df = test_df.withColumn(\"events_data_timestamp_unixtime_ms_pst_date_calc\", f.from_utc_timestamp(f.from_unixtime(\"start_date\", \"yyyy-MM-dd\"), \"America/Los_Angeles\"))\n",
        "test_df = test_df.withColumn(\"events_data_timestamp_unixtime_ms_utc_calc\", f.from_utc_timestamp(f.from_unixtime(\"start_date\", \"yyyy-MM-dd HH:mm:ss\"), \"UTC\"))\n",
        "test_df = test_df.withColumn(\"events_data_timestamp_unixtime_ms_utc_date_calc\", f.from_utc_timestamp(f.from_unixtime(\"start_date\", \"yyyy-MM-dd\"), \"UTC\"))\n",
        "test_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5RoSgyYhEll"
      },
      "outputs": [],
      "source": [
        "# test_df = test_df.withColumn(\"new_dataFields_createdAt\", f.from_unixtime(f.unix_timestamp(\"dataFields_createdAt\"),'yyyy-MM-dd HH:mm:ss').cast(StringType())) \n",
        "# test_df.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f229vqYRkxZ7",
        "outputId": "905550c9-9d54-4438-c078-5fcf387515e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------------+----------+---------------------------------+--------------------+-----------+------------------------------------------+-----------------------------------------------+------------------------------------------+-----------------------------------------------+\n",
            "| id|            attr|start_date|events_data_timestamp_unixtime_ms|dataFields_createdAt|report_date|events_data_timestamp_unixtime_ms_pst_calc|events_data_timestamp_unixtime_ms_pst_date_calc|events_data_timestamp_unixtime_ms_utc_calc|events_data_timestamp_unixtime_ms_utc_date_calc|\n",
            "+---+----------------+----------+---------------------------------+--------------------+-----------+------------------------------------------+-----------------------------------------------+------------------------------------------+-----------------------------------------------+\n",
            "|  1|          Hello!|1643937003|                    1643825926704|2022-02-02 18:18:...| 03/02/2022|                       2022-02-03 17:10:03|                            2022-02-03 16:00:00|                       2022-02-04 01:10:03|                            2022-02-04 00:00:00|\n",
            "|  4|    Hello World!|1643937003|                    1643825926704|2022-02-02 18:18:...| 03/02/2022|                       2022-02-03 17:10:03|                            2022-02-03 16:00:00|                       2022-02-04 01:10:03|                            2022-02-04 00:00:00|\n",
            "|  2|    Hello Spark!|1644122255|                              NaN|2022-02-02 18:18:...| 05/02/2022|                       2022-02-05 20:37:35|                            2022-02-05 16:00:00|                       2022-02-06 04:37:35|                            2022-02-06 00:00:00|\n",
            "|  3|Hello Old World!|1643991898|                    1643825926704|2022-02-02 18:18:...| 04/02/2022|                       2022-02-04 08:24:58|                            2022-02-03 16:00:00|                       2022-02-04 16:24:58|                            2022-02-04 00:00:00|\n",
            "|  5|    Hello Spark!|       NaN|                              NaN|2022-02-02 18:18:...|       null|                                      null|                                           null|                                      null|                                           null|\n",
            "+---+----------------+----------+---------------------------------+--------------------+-----------+------------------------------------------+-----------------------------------------------+------------------------------------------+-----------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVTfngXWegIe",
        "outputId": "3bc0f3d0-2134-42d5-8af1-e3bf9218324a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+-----+----+----+\n",
            "|        report_date|month|year| day|\n",
            "+-------------------+-----+----+----+\n",
            "|2022-02-03 17:10:03|    2|2022|   3|\n",
            "|2022-02-03 17:10:03|    2|2022|   3|\n",
            "|2022-02-05 20:37:35|    2|2022|   5|\n",
            "|2022-02-04 08:24:58|    2|2022|   4|\n",
            "|               null| null|null|null|\n",
            "+-------------------+-----+----+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import month , year, dayofmonth\n",
        "\n",
        "test_df = test_df.withColumn('month',month(test_df.report_date))\n",
        "test_df = test_df.withColumn('year',year(test_df.report_date))\n",
        "test_df = test_df.withColumn('day',dayofmonth(test_df.report_date))\n",
        "test_df[['report_date', 'month', 'year', 'day']].show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyOckf5IrGH6"
      },
      "outputs": [],
      "source": [
        "test_df.createOrReplaceTempView(\"test_df_temp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "33vhJjNRimpx",
        "outputId": "8d16ccc5-45e4-4880-daca-d5591276eec7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2022-02-03 17:10:03'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# spark.sql(\"select to_date(dataFields_createdAt, 'yyyy-MM-dd HH:mm:ss') as test3 from test_df_temp\").show()\n",
        "\n",
        "\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "import math\n",
        "# from pyspark.sql.functions import udf\n",
        "\n",
        "def convert_time_format(val, format, tz):\n",
        "    if val is None or val is math.nan:\n",
        "        return None\n",
        "    dt = datetime.fromtimestamp(int(val))\n",
        "    dt = dt.astimezone(pytz.timezone(tz))\n",
        "    return dt.strftime(format)\n",
        "        \n",
        "    \n",
        "\n",
        "# convert_time_format_udf = udf(convert_time_format,StringType())  \n",
        "\n",
        "convert_time_format('1643937003', '%Y-%m-%d %H:%M:%S', 'America/Los_Angeles')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqr24jf_DV-P",
        "outputId": "6e26029d-40a3-4f04-987d-0ac6a7387497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------------+----------+---------------------------------+--------------------+-------------------+------------------------------------------+-----------------------------------------------+------------------------------------------+-----------------------------------------------+------------------------+\n",
            "| id|            attr|start_date|events_data_timestamp_unixtime_ms|dataFields_createdAt|        report_date|events_data_timestamp_unixtime_ms_pst_calc|events_data_timestamp_unixtime_ms_pst_date_calc|events_data_timestamp_unixtime_ms_utc_calc|events_data_timestamp_unixtime_ms_utc_date_calc|dataFields_createdAt_new|\n",
            "+---+----------------+----------+---------------------------------+--------------------+-------------------+------------------------------------------+-----------------------------------------------+------------------------------------------+-----------------------------------------------+------------------------+\n",
            "|  1|          Hello!|1643937003|                    1643825926704|2022-02-02 18:18:...|2022-02-03 17:10:03|                       2022-02-03 17:10:03|                            2022-02-03 16:00:00|                       2022-02-04 01:10:03|                            2022-02-04 00:00:00|     2022-02-02 10:18:46|\n",
            "|  4|    Hello World!|1643937003|                    1643825926704|2022-02-02 18:18:...|2022-02-03 17:10:03|                       2022-02-03 17:10:03|                            2022-02-03 16:00:00|                       2022-02-04 01:10:03|                            2022-02-04 00:00:00|     2022-02-02 10:18:46|\n",
            "|  2|    Hello Spark!|1644122255|                              NaN|2022-02-02 18:18:...|2022-02-05 20:37:35|                       2022-02-05 20:37:35|                            2022-02-05 16:00:00|                       2022-02-06 04:37:35|                            2022-02-06 00:00:00|     2022-02-02 10:18:46|\n",
            "|  3|Hello Old World!|1643991898|                    1643825926704|2022-02-02 18:18:...|2022-02-04 08:24:58|                       2022-02-04 08:24:58|                            2022-02-03 16:00:00|                       2022-02-04 16:24:58|                            2022-02-04 00:00:00|     2022-02-02 10:18:46|\n",
            "|  5|    Hello Spark!|       NaN|                              NaN|2022-02-02 18:18:...|               null|                                      null|                                           null|                                      null|                                           null|     2022-02-02 10:18:46|\n",
            "+---+----------------+----------+---------------------------------+--------------------+-------------------+------------------------------------------+-----------------------------------------------+------------------------------------------+-----------------------------------------------+------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_df = test_df.withColumn(\n",
        "                \"dataFields_createdAt_new\", convert_time_format_udf(test_df[\"dataFields_createdAt\"], lit('%Y-%m-%d %H:%M:%S'), lit(\"America/Los_Angeles\"))\n",
        "            )\n",
        "test_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA9kPuv_afm_",
        "outputId": "c56cace5-1a22-4501-f4b7-9df1360659e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------+\n",
            "|events_data_timestamp_unixtime_ms|\n",
            "+---------------------------------+\n",
            "|                       1643825926|\n",
            "|                       1643825926|\n",
            "|                              NaN|\n",
            "|                       1643825926|\n",
            "|                              NaN|\n",
            "+---------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "new_df = spark.sql(\"select LEFT(events_data_timestamp_unixtime_ms, 10) AS events_data_timestamp_unixtime_ms  from test_df_temp\")\n",
        "new_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13ivEMISbPNv",
        "outputId": "a8d50a04-12ec-4c75-9d15-5c91042867aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------+-------------------+-------------------------------------------+\n",
            "|events_data_timestamp_unixtime_ms|       report_date2|events_data_timestamp_unixtime_ms_pst_calc2|\n",
            "+---------------------------------+-------------------+-------------------------------------------+\n",
            "|                       1643825926|2022-02-02 10:18:46|                        2022-02-02 10:18:46|\n",
            "|                       1643825926|2022-02-02 10:18:46|                        2022-02-02 10:18:46|\n",
            "|                              NaN|               null|                                       null|\n",
            "|                       1643825926|2022-02-02 10:18:46|                        2022-02-02 10:18:46|\n",
            "|                              NaN|               null|                                       null|\n",
            "+---------------------------------+-------------------+-------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "new_df = new_df.withColumn(\"report_date2\", f.from_utc_timestamp(f.from_unixtime(\"events_data_timestamp_unixtime_ms\", \"yyyy-MM-dd hh:mmaa\"), \"America/Los_Angeles\"))\n",
        "new_df = new_df.withColumn(\"events_data_timestamp_unixtime_ms_pst_calc2\", f.from_utc_timestamp(f.from_unixtime(\"events_data_timestamp_unixtime_ms\", \"yyyy-MM-dd HH:mm:ss\"), \"America/Los_Angeles\"))\n",
        "new_df[['events_data_timestamp_unixtime_ms', 'report_date2', 'events_data_timestamp_unixtime_ms_pst_calc2']].show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yxs8_h0rQIC",
        "outputId": "63bb6377-f109-46cf-d7e4-97e625bf2003"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['aa', 'Pa', 'Pa']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "re.split('(?=[A-Z])', \"aaPaPa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBKRXFBnWz-e",
        "outputId": "ff7a7184-8def-4213-9bac-fc3162c9eb8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------+\n",
            "|src_id|      src_attr|\n",
            "+------+--------------+\n",
            "|     1|  Hello World!|\n",
            "|     2|Hello PySpark!|\n",
            "|     4|  Hello Scala!|\n",
            "+------+--------------+\n",
            "\n",
            "root\n",
            " |-- src_id: integer (nullable = true)\n",
            " |-- src_attr: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Source data set\n",
        "data_source = [\n",
        "Row(1, \"Hello World!\"),\n",
        "Row(2, \"Hello PySpark!\"),\n",
        "Row(4, \"Hello Scala!\")\n",
        "]\n",
        "schema_source = StructType([\n",
        "StructField(\"src_id\", IntegerType(), True),\n",
        "StructField(\"src_attr\", StringType(), True)\n",
        "])\n",
        "df_source = sqlContext.createDataFrame(\n",
        "sc.parallelize(data_source),\n",
        "schema_source\n",
        ")\n",
        "df_source.show()\n",
        "df_source.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLRzb8u1XDev"
      },
      "outputs": [],
      "source": [
        "high_date = datetime.strptime('9999-12-31', '%Y-%m-%d').date()\n",
        "print(high_date)\n",
        "current_date = datetime.today().date()\n",
        "print(current_date)\n",
        "# Prepare for merge - Added effective and end date\n",
        "df_source_new = df_source.withColumn('src_start_date', lit(\n",
        "current_date)).withColumn('src_end_date', lit(high_date))\n",
        "# FULL Merge, join on key column and also high date column to make only join to the latest records\n",
        "df_merge = df_target.join(df_source_new, (df_source_new.src_id == df_target.id) &\n",
        "(df_source_new.src_end_date == df_target.end_date), how='fullouter')\n",
        "# Derive new column to indicate the action\n",
        "df_merge = df_merge.withColumn('action',\n",
        "when(df_merge.attr != df_merge.src_attr, 'UPSERT')\n",
        ".when(df_merge.src_id.isNull() & df_merge.is_current, 'DELETE')\n",
        ".when(df_merge.id.isNull(), 'INSERT')\n",
        ".otherwise('NOACTION')\n",
        ")\n",
        "df_merge.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3xtZGdcXHBV"
      },
      "outputs": [],
      "source": [
        "# Generate the new data frames based on action code\n",
        "column_names = ['id', 'attr', 'is_current',\n",
        "'is_deleted', 'start_date', 'end_date']\n",
        "# For records that needs no action\n",
        "df_merge_p1 = df_merge.filter(\n",
        "df_merge.action == 'NOACTION').select(column_names)\n",
        "# For records that needs insert only\n",
        "df_merge_p2 = df_merge.filter(df_merge.action == 'INSERT').select(df_merge.src_id.alias('id'),\n",
        "df_merge.src_attr.alias(\n",
        "'attr'),\n",
        "lit(True).alias(\n",
        "'is_current'),\n",
        "lit(False).alias(\n",
        "'is_deleted'),\n",
        "df_merge.src_start_date.alias(\n",
        "'start_date'),\n",
        "df_merge.src_end_date.alias(\n",
        "'end_date')\n",
        ")\n",
        "# For records that needs to be deleted\n",
        "df_merge_p3 = df_merge.filter(\n",
        "df_merge.action == 'DELETE').select(column_names).withColumn('is_current', lit(False)).withColumn('is_deleted', lit(True))\n",
        "# For records that needs to be expired and then inserted\n",
        "df_merge_p4_1 = df_merge.filter(df_merge.action == 'UPSERT').select(df_merge.src_id.alias('id'),\n",
        "df_merge.src_attr.alias(\n",
        "'attr'),\n",
        "lit(True).alias(\n",
        "'is_current'),\n",
        "lit(False).alias(\n",
        "'is_deleted'),\n",
        "df_merge.src_start_date.alias(\n",
        "'start_date'),\n",
        "df_merge.src_end_date.alias(\n",
        "'end_date')\n",
        ")\n",
        "df_merge_p4_2 = df_merge.filter(\n",
        "df_merge.action == 'UPSERT').withColumn(\n",
        "'end_date', date_sub(df_merge.src_start_date, 1)).withColumn(\n",
        "'is_current', lit(False)).withColumn(\n",
        "'is_deleted', lit(False)).select(column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgMT4cyOXLEF"
      },
      "outputs": [],
      "source": [
        "# Union all records together\n",
        "df_merge_final = df_merge_p1.unionAll(df_merge_p2).unionAll(\n",
        "df_merge_p3).unionAll(df_merge_p4_1).unionAll(df_merge_p4_2)\n",
        "df_merge_final.orderBy(['id', 'start_date']).show()\n",
        "# At last, you can overwrite existing data using this new data frame.\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSprlTpaXUSP",
        "outputId": "adddcbc5-5c6a-49e2-9dc1-83c28f0a6a07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.20.49-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting botocore<1.24.0,>=1.23.49\n",
            "  Downloading botocore-1.23.49-py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.5 MB 49.4 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.1-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.49->boto3) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 138 kB 64.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.49->boto3) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.8 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.20.49 botocore-1.23.49 jmespath-0.10.0 s3transfer-0.5.1 urllib3-1.26.8\n"
          ]
        }
      ],
      "source": [
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evl0KGkOyWRH",
        "outputId": "8109d44b-c077-4984-834e-31405c1fa70a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mysql-connector==2.2.9\n",
            "  Downloading mysql-connector-2.2.9.tar.gz (11.9 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.9 MB 5.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mysql-connector\n",
            "  Building wheel for mysql-connector (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysql-connector: filename=mysql_connector-2.2.9-cp37-cp37m-linux_x86_64.whl size=247965 sha256=90df9c26b80de7db015269461e382fab1de4b4812dc862b88ff9ce9ad6d58526\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/2f/c3/692fc7fc1f0d8c06b9175d94f0fc30f4f92348f5df5af1b8b7\n",
            "Successfully built mysql-connector\n",
            "Installing collected packages: mysql-connector\n",
            "Successfully installed mysql-connector-2.2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install mysql-connector==2.2.9\n",
        "import mysql.connector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52GOLNqkyub-",
        "outputId": "d1a33e09-9cfb-4b1d-ef85-d6b395b3b4a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting snowflake-connector-python==2.7.2\n",
            "  Downloading snowflake_connector_python-2.7.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.4 MB 27 kB/s \n",
            "\u001b[?25hCollecting pycryptodomex!=3.5.0,<4.0.0,>=3.2\n",
            "  Downloading pycryptodomex-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0 MB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from snowflake-connector-python==2.7.2) (2021.10.8)\n",
            "Collecting pyjwt<3.0.0\n",
            "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from snowflake-connector-python==2.7.2) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.7/dist-packages (from snowflake-connector-python==2.7.2) (2.23.0)\n",
            "Collecting pyOpenSSL<22.0.0,>=16.2.0\n",
            "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.7/dist-packages (from snowflake-connector-python==2.7.2) (1.15.0)\n",
            "Collecting oscrypto<2.0.0\n",
            "  Downloading oscrypto-1.2.1-py2.py3-none-any.whl (192 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 192 kB 52.3 MB/s \n",
            "\u001b[?25hCollecting asn1crypto<2.0.0,>0.24.0\n",
            "  Downloading asn1crypto-1.4.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104 kB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>34.0.0 in /usr/local/lib/python3.7/dist-packages (from snowflake-connector-python==2.7.2) (57.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from snowflake-connector-python==2.7.2) (2.0.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from snowflake-connector-python==2.7.2) (2.10)\n",
            "Collecting cryptography<36.0.0,>=3.1.0\n",
            "  Downloading cryptography-35.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.5 MB 30.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python==2.7.2) (2.21)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL<22.0.0,>=16.2.0->snowflake-connector-python==2.7.2) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->snowflake-connector-python==2.7.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->snowflake-connector-python==2.7.2) (3.0.4)\n",
            "Installing collected packages: cryptography, asn1crypto, pyOpenSSL, pyjwt, pycryptodomex, oscrypto, snowflake-connector-python\n",
            "Successfully installed asn1crypto-1.4.0 cryptography-35.0.0 oscrypto-1.2.1 pyOpenSSL-21.0.0 pycryptodomex-3.14.1 pyjwt-2.3.0 snowflake-connector-python-2.7.2\n"
          ]
        }
      ],
      "source": [
        "! pip install snowflake-connector-python==2.7.2\n",
        "from snowflake.connector import Connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsd7evFGy_FM",
        "outputId": "1ff8af90-b350-4359-bee2-4d55746b4de4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datetime.datetime(2022, 2, 2, 6, 10, 17, 824990, tzinfo=tzlocal())"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dateutil import parser\n",
        "import pytz\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.functions import unix_timestamp\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql.functions import month , year, dayofmonth\n",
        "\n",
        "parser.parse(\"2022-02-02T06:10:17.824990Z\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7ZBbDCjNWGS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1_I3eeoy4eg"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/data_202202151947.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMqDHVu5zbnA",
        "outputId": "62f42f99-dc9f-4072-f5a1-42d5712b2607"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(380, 19)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyg6rXddzfvi"
      },
      "outputs": [],
      "source": [
        "df.query(\"upload_timestamp != 'skipped'\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSeg-5INz4Qq",
        "outputId": "98284cc1-66db-4fe4-e6e4-50acb1539bac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(149, 19)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "TW9Du0xWz5OC",
        "outputId": "8b34b132-b280-4c60-f3f1-4326cc1068c8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4c75f404-d100-4cc2-a60f-f6b3894c8710\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handle</th>\n",
              "      <th>handle_id</th>\n",
              "      <th>handle_name</th>\n",
              "      <th>video_title</th>\n",
              "      <th>video_id</th>\n",
              "      <th>upload_timestamp</th>\n",
              "      <th>video_duration</th>\n",
              "      <th>views</th>\n",
              "      <th>likes</th>\n",
              "      <th>comments</th>\n",
              "      <th>shares</th>\n",
              "      <th>profile_following</th>\n",
              "      <th>profile_follower</th>\n",
              "      <th>profile_likes</th>\n",
              "      <th>profile_total_videos</th>\n",
              "      <th>permalink_url</th>\n",
              "      <th>music_id</th>\n",
              "      <th>music_author</th>\n",
              "      <th>handle_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>estylecollective</td>\n",
              "      <td>NaN</td>\n",
              "      <td>E! Style Collective</td>\n",
              "      <td>#khiryofficial came, designed, and conquered t...</td>\n",
              "      <td>7.064300e+18</td>\n",
              "      <td>34:59.5</td>\n",
              "      <td>24.262</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>234</td>\n",
              "      <td>2449</td>\n",
              "      <td>30</td>\n",
              "      <td>https://www.tiktok.com/@estylecollective/video...</td>\n",
              "      <td>6.99965E+18</td>\n",
              "      <td>I Just Wanna Know - Luke Reeves</td>\n",
              "      <td>https://www.tiktok.com/@estylecollective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>enews</td>\n",
              "      <td>NaN</td>\n",
              "      <td>E! News</td>\n",
              "      <td>It's #nationalpizzaday and what better way to ...</td>\n",
              "      <td>7.062860e+18</td>\n",
              "      <td>32:23.4</td>\n",
              "      <td>23.798</td>\n",
              "      <td>10.4K</td>\n",
              "      <td>509</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>183</td>\n",
              "      <td>2M</td>\n",
              "      <td>32.8M</td>\n",
              "      <td>30</td>\n",
              "      <td>https://www.tiktok.com/@enews/video/7062859396...</td>\n",
              "      <td>7.06286E+18</td>\n",
              "      <td>original sound - E! News</td>\n",
              "      <td>https://www.tiktok.com/@enews</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>telemundo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Telemundo</td>\n",
              "      <td>Feliz juernesðŸŽ‰ðŸ˜… @manuelturizoz @nio garcia @an...</td>\n",
              "      <td>7.058050e+18</td>\n",
              "      <td>1/28/2022 0:00</td>\n",
              "      <td>9.448</td>\n",
              "      <td>340.2K</td>\n",
              "      <td>0</td>\n",
              "      <td>106</td>\n",
              "      <td>41</td>\n",
              "      <td>123</td>\n",
              "      <td>2M</td>\n",
              "      <td>12M</td>\n",
              "      <td>30</td>\n",
              "      <td>https://www.tiktok.com/@telemundo/video/705805...</td>\n",
              "      <td>7.05805E+18</td>\n",
              "      <td>original sound - Telemundo</td>\n",
              "      <td>https://www.tiktok.com/@telemundo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>enews</td>\n",
              "      <td>NaN</td>\n",
              "      <td>E! News</td>\n",
              "      <td>Sheâ€™ll always be Jenny from the Block. #MarryMe</td>\n",
              "      <td>7.063520e+18</td>\n",
              "      <td>31:48.3</td>\n",
              "      <td>12.049</td>\n",
              "      <td>8608</td>\n",
              "      <td>313</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>183</td>\n",
              "      <td>2M</td>\n",
              "      <td>32.8M</td>\n",
              "      <td>30</td>\n",
              "      <td>https://www.tiktok.com/@enews/video/7063521947...</td>\n",
              "      <td>7.04954E+18</td>\n",
              "      <td>original sound - Maggie Winters</td>\n",
              "      <td>https://www.tiktok.com/@enews</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>e_entertainment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>E! Entertainment</td>\n",
              "      <td>when artificial insemination is the spark that...</td>\n",
              "      <td>7.058350e+18</td>\n",
              "      <td>1/29/2022 0:00</td>\n",
              "      <td>11.767</td>\n",
              "      <td>28.5K</td>\n",
              "      <td>1241</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>74</td>\n",
              "      <td>1.2M</td>\n",
              "      <td>31M</td>\n",
              "      <td>30</td>\n",
              "      <td>https://www.tiktok.com/@e_entertainment/video/...</td>\n",
              "      <td>7.05835E+18</td>\n",
              "      <td>original sound - E! Entertainment</td>\n",
              "      <td>https://www.tiktok.com/@e_entertainment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c75f404-d100-4cc2-a60f-f6b3894c8710')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c75f404-d100-4cc2-a60f-f6b3894c8710 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c75f404-d100-4cc2-a60f-f6b3894c8710');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               handle  ...                                handle_url\n",
              "103  estylecollective  ...  https://www.tiktok.com/@estylecollective\n",
              "83              enews  ...             https://www.tiktok.com/@enews\n",
              "212         telemundo  ...         https://www.tiktok.com/@telemundo\n",
              "78              enews  ...             https://www.tiktok.com/@enews\n",
              "44    e_entertainment  ...   https://www.tiktok.com/@e_entertainment\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "spark_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
