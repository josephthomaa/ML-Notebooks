{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark_detail.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzPtUUWFuAdL"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7egDa8M2uIyY",
        "outputId": "84179621-419f-4c0f-9ded-58f2c6d6c193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-03 09:44:58--  https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 272637746 (260M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.2.1-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-3.2.1-bin-had 100%[===================>] 260.01M   226MB/s    in 1.2s    \n",
            "\n",
            "2022-03-03 09:45:10 (226 MB/s) - ‘spark-3.2.1-bin-hadoop2.7.tgz’ saved [272637746/272637746]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.2.1-bin-hadoop2.7.tgz\n"
      ],
      "metadata": {
        "id": "LgYd9fXpuKKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "usgPDZiDuQVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7\"\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "EU8zVyzruT2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "cel5VdBZuaNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf, lit, when, date_sub, col\n",
        "from pyspark.sql.types import ArrayType, IntegerType, StructType, StructField, StringType\n",
        "from pyspark.sql.types import BooleanType, DateType, DoubleType, FloatType\n",
        "import json\n",
        "from pyspark import SparkContext, SparkConf, SQLContext\n",
        "from pyspark.sql import Row\n",
        "from datetime import datetime\n",
        "from pyspark.sql.functions import current_date\n",
        "\n",
        "# conf = SparkConf().setAppName('Colab').setMaster('local')\n",
        "# sc = SparkContext(conf=spark)\n",
        "sqlContext = SQLContext(spark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODycO0EvueMw",
        "outputId": "dd80c6ca-22e7-46ab-a006-d27acaf6f839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stock data sample"
      ],
      "metadata": {
        "id": "knlbx9Db-Xqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upload_path = \"/content/data\"\n",
        "\n",
        "checkpoint_path = '/content/stocks_data/_checkpoints'\n",
        "write_path = '/content/stocks_data'"
      ],
      "metadata": {
        "id": "_xFTvJmkLVse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.read.option(\"header\",True).csv(upload_path)\n",
        "cust_schema = df2.schema"
      ],
      "metadata": {
        "id": "SS907KkPMBrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the stream to begin reading incoming files from the\n",
        "# upload_path location.\n",
        "df = spark.readStream.format('cloudFiles').option('cloudFiles.format', 'csv').option('header', 'true').schema(cust_schema).load(upload_path)\n",
        "\n",
        "# Start the stream.\n",
        "# Use the checkpoint_path location to keep a record of all files that\n",
        "# have already been uploaded to the upload_path location.\n",
        "# For those that have been uploaded since the last check,\n",
        "# write the newly-uploaded files' data to the write_path location.\n",
        "df.writeStream.format('parquet') \\\n",
        "  .option('checkpointLocation', checkpoint_path) \\\n",
        "  .option('path', write_path) \\\n",
        "  .start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "id": "oxn0ucSsMOYG",
        "outputId": "9f6c577d-d872-4928-de39-7dadd8d3e8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-802f31f6fbd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set up the stream to begin reading incoming files from the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# upload_path location.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cloudFiles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cloudFiles.format'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'header'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcust_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Start the stream.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 raise ValueError(\"If the path is provided for stream, it needs to be a \" +\n\u001b[1;32m    451\u001b[0m                                  \"non-empty string. List of paths are not supported.\")\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o74.load.\n: java.lang.ClassNotFoundException: \nFailed to find data source: cloudFiles. Please find packages at\nhttp://spark.apache.org/third-party-projects.html\n       \n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedToFindDataSourceError(QueryExecutionErrors.scala:443)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:670)\n\tat org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:156)\n\tat org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:209)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: cloudFiles.DefaultSource\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:656)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:656)\n\tat scala.util.Failure.orElse(Try.scala:224)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:656)\n\t... 14 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Reading all the csv files from stocks dir in colab\n",
        "from  pyspark.sql.functions import input_file_name\n",
        "df = spark.read.option(\"header\",True).csv('/content/stocks/*').withColumn(\"filename\", input_file_name())"
      ],
      "metadata": {
        "id": "YqMnaUZSXixS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERl_e7w-XoD8",
        "outputId": "7b6e816e-2d20-4d68-acdd-d69b341bb949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(SC_CODE='500002', SC_NAME='ABB LTD.    ', SC_GROUP='A ', SC_TYPE='Q', OPEN='1860.25', HIGH='1892.00', LOW='1846.00', CLOSE='1873.20', LAST='1864.00', PREVCLOSE='1854.95', NO_TRADES='768', NO_OF_SHRS='4120', NET_TURNOV='7666507.00', TDCLOINDI=None, filename='file:/content/stocks/EQ041021.CSV'),\n",
              " Row(SC_CODE='500003', SC_NAME='AEGIS LOGIS ', SC_GROUP='A ', SC_TYPE='Q', OPEN='230.25', HIGH='233.35', LOW='228.00', CLOSE='229.35', LAST='229.35', PREVCLOSE='228.95', NO_TRADES='2475', NO_OF_SHRS='54056', NET_TURNOV='12441733.00', TDCLOINDI=None, filename='file:/content/stocks/EQ041021.CSV'),\n",
              " Row(SC_CODE='500008', SC_NAME='AMAR RAJA BA', SC_GROUP='A ', SC_TYPE='Q', OPEN='774.50', HIGH='774.85', LOW='762.00', CLOSE='766.15', LAST='766.15', PREVCLOSE='765.50', NO_TRADES='2642', NO_OF_SHRS='63238', NET_TURNOV='48593068.00', TDCLOINDI=None, filename='file:/content/stocks/EQ041021.CSV'),\n",
              " Row(SC_CODE='500009', SC_NAME='A.SARABHAI  ', SC_GROUP='X ', SC_TYPE='Q', OPEN='30.75', HIGH='31.00', LOW='30.55', CLOSE='30.65', LAST='30.65', PREVCLOSE='30.65', NO_TRADES='728', NO_OF_SHRS='145196', NET_TURNOV='4462266.00', TDCLOINDI=None, filename='file:/content/stocks/EQ041021.CSV'),\n",
              " Row(SC_CODE='500010', SC_NAME='HDFC        ', SC_GROUP='A ', SC_TYPE='Q', OPEN='2740.00', HIGH='2769.00', LOW='2721.05', CLOSE='2725.00', LAST='2725.00', PREVCLOSE='2712.25', NO_TRADES='6175', NO_OF_SHRS='83389', NET_TURNOV='228666721.00', TDCLOINDI=None, filename='file:/content/stocks/EQ041021.CSV')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "def get_date(value):\n",
        "  f_name, _ = os.path.splitext(os.path.basename(value))\n",
        "  col_date = datetime. strptime(f_name[-6:], '%d%m%y').date()\n",
        "  return str(col_date)\n",
        "\n",
        "print(get_date('file:/content/stocks/EQ041021.CSV'))\n",
        "\n",
        "get_date_udf_func = udf(get_date,StringType()) \n",
        "# spark.udf.register(\"get_date_udf_func\", get_date,StringType())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1Ra6uuhX1tr",
        "outputId": "d198ff81-f635-4aa2-b131-cb77f595d25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import month , year, dayofmonth\n",
        "\n",
        "df = df.withColumn(\"closing_date\", get_date_udf_func(df[\"filename\"]))"
      ],
      "metadata": {
        "id": "xPMbIYYncVrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(1, truncate=False)\n",
        "df_path = 'file:/content/stock_merged.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PYqdVbOdY39",
        "outputId": "302f7e22-af52-40ba-dd8c-c1860b72d556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+--------+-------+-------+-------+-------+-------+-------+---------+---------+----------+----------+---------+---------------------------------+------------+\n",
            "|SC_CODE|SC_NAME     |SC_GROUP|SC_TYPE|OPEN   |HIGH   |LOW    |CLOSE  |LAST   |PREVCLOSE|NO_TRADES|NO_OF_SHRS|NET_TURNOV|TDCLOINDI|filename                         |closing_date|\n",
            "+-------+------------+--------+-------+-------+-------+-------+-------+-------+---------+---------+----------+----------+---------+---------------------------------+------------+\n",
            "|500002 |ABB LTD.    |A       |Q      |1860.25|1892.00|1846.00|1873.20|1864.00|1854.95  |768      |4120      |7666507.00|null     |file:/content/stocks/EQ041021.CSV|2021-10-04  |\n",
            "+-------+------------+--------+-------+-------+-------+-------+-------+-------+---------+---------+----------+----------+---------+---------------------------------+------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groups = [x[0] for x in df.select(\"SC_CODE\").distinct().collect()]\n",
        "groups[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QYa6rvpJCB2W",
        "outputId": "b79061f2-d522-4ab5-bbc2-322669e1bff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'508905'"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groups[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p7RJ8iHChlU",
        "outputId": "26ed376b-17db-4b72-94a5-a1e16c842831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['500148', '500253', '501314', '507514', '507525']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.options(delimiter='\\u0001').option('nullValue', None).mode(\"overwrite\").csv(df_path)"
      ],
      "metadata": {
        "id": "si2-QAnReUlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_pd = df.toPandas()\n",
        "new_pd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "IfiBsRdKfKI2",
        "outputId": "a0218550-9562-471a-cdcc-7f989215982b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bd102f47-ea3c-47b4-a87b-394d74c5222e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SC_CODE</th>\n",
              "      <th>SC_NAME</th>\n",
              "      <th>SC_GROUP</th>\n",
              "      <th>SC_TYPE</th>\n",
              "      <th>OPEN</th>\n",
              "      <th>HIGH</th>\n",
              "      <th>LOW</th>\n",
              "      <th>CLOSE</th>\n",
              "      <th>LAST</th>\n",
              "      <th>PREVCLOSE</th>\n",
              "      <th>NO_TRADES</th>\n",
              "      <th>NO_OF_SHRS</th>\n",
              "      <th>NET_TURNOV</th>\n",
              "      <th>TDCLOINDI</th>\n",
              "      <th>filename</th>\n",
              "      <th>closing_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500002</td>\n",
              "      <td>ABB LTD.</td>\n",
              "      <td>A</td>\n",
              "      <td>Q</td>\n",
              "      <td>1860.25</td>\n",
              "      <td>1892.00</td>\n",
              "      <td>1846.00</td>\n",
              "      <td>1873.20</td>\n",
              "      <td>1864.00</td>\n",
              "      <td>1854.95</td>\n",
              "      <td>768</td>\n",
              "      <td>4120</td>\n",
              "      <td>7666507.00</td>\n",
              "      <td>None</td>\n",
              "      <td>file:/content/stocks/EQ041021.CSV</td>\n",
              "      <td>2021-10-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500003</td>\n",
              "      <td>AEGIS LOGIS</td>\n",
              "      <td>A</td>\n",
              "      <td>Q</td>\n",
              "      <td>230.25</td>\n",
              "      <td>233.35</td>\n",
              "      <td>228.00</td>\n",
              "      <td>229.35</td>\n",
              "      <td>229.35</td>\n",
              "      <td>228.95</td>\n",
              "      <td>2475</td>\n",
              "      <td>54056</td>\n",
              "      <td>12441733.00</td>\n",
              "      <td>None</td>\n",
              "      <td>file:/content/stocks/EQ041021.CSV</td>\n",
              "      <td>2021-10-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500008</td>\n",
              "      <td>AMAR RAJA BA</td>\n",
              "      <td>A</td>\n",
              "      <td>Q</td>\n",
              "      <td>774.50</td>\n",
              "      <td>774.85</td>\n",
              "      <td>762.00</td>\n",
              "      <td>766.15</td>\n",
              "      <td>766.15</td>\n",
              "      <td>765.50</td>\n",
              "      <td>2642</td>\n",
              "      <td>63238</td>\n",
              "      <td>48593068.00</td>\n",
              "      <td>None</td>\n",
              "      <td>file:/content/stocks/EQ041021.CSV</td>\n",
              "      <td>2021-10-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500009</td>\n",
              "      <td>A.SARABHAI</td>\n",
              "      <td>X</td>\n",
              "      <td>Q</td>\n",
              "      <td>30.75</td>\n",
              "      <td>31.00</td>\n",
              "      <td>30.55</td>\n",
              "      <td>30.65</td>\n",
              "      <td>30.65</td>\n",
              "      <td>30.65</td>\n",
              "      <td>728</td>\n",
              "      <td>145196</td>\n",
              "      <td>4462266.00</td>\n",
              "      <td>None</td>\n",
              "      <td>file:/content/stocks/EQ041021.CSV</td>\n",
              "      <td>2021-10-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500010</td>\n",
              "      <td>HDFC</td>\n",
              "      <td>A</td>\n",
              "      <td>Q</td>\n",
              "      <td>2740.00</td>\n",
              "      <td>2769.00</td>\n",
              "      <td>2721.05</td>\n",
              "      <td>2725.00</td>\n",
              "      <td>2725.00</td>\n",
              "      <td>2712.25</td>\n",
              "      <td>6175</td>\n",
              "      <td>83389</td>\n",
              "      <td>228666721.00</td>\n",
              "      <td>None</td>\n",
              "      <td>file:/content/stocks/EQ041021.CSV</td>\n",
              "      <td>2021-10-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd102f47-ea3c-47b4-a87b-394d74c5222e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd102f47-ea3c-47b4-a87b-394d74c5222e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd102f47-ea3c-47b4-a87b-394d74c5222e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  SC_CODE       SC_NAME  ...                           filename closing_date\n",
              "0  500002  ABB LTD.      ...  file:/content/stocks/EQ041021.CSV   2021-10-04\n",
              "1  500003  AEGIS LOGIS   ...  file:/content/stocks/EQ041021.CSV   2021-10-04\n",
              "2  500008  AMAR RAJA BA  ...  file:/content/stocks/EQ041021.CSV   2021-10-04\n",
              "3  500009  A.SARABHAI    ...  file:/content/stocks/EQ041021.CSV   2021-10-04\n",
              "4  500010  HDFC          ...  file:/content/stocks/EQ041021.CSV   2021-10-04\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_pd.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B29Si1dIg53u",
        "outputId": "f26c3501-0c52-4c58-d5c4-4022842bb358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(744838, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_pd.to_csv('stock_merge.csv')"
      ],
      "metadata": {
        "id": "iQAtoQBlgsJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TaKQPeg_gsGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = spark.read.option(\"header\",True).csv('file:/content/stock_merge.csv')\n",
        "df_merged.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4vKZ0wGf-Mq",
        "outputId": "6acd66a6-51b9-40a5-ceb4-b91ca8a588ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------------+--------+-------+-------+--------+-------+--------+--------+---------+---------+----------+------------+---------+--------------------+------------+\n",
            "|_c0|SC_CODE|     SC_NAME|SC_GROUP|SC_TYPE|   OPEN|    HIGH|    LOW|   CLOSE|    LAST|PREVCLOSE|NO_TRADES|NO_OF_SHRS|  NET_TURNOV|TDCLOINDI|            filename|closing_date|\n",
            "+---+-------+------------+--------+-------+-------+--------+-------+--------+--------+---------+---------+----------+------------+---------+--------------------+------------+\n",
            "|  0| 500002|ABB LTD.    |      A |      Q|1860.25| 1892.00|1846.00| 1873.20| 1864.00|  1854.95|      768|      4120|  7666507.00|     null|file:/content/sto...|  2021-10-04|\n",
            "|  1| 500003|AEGIS LOGIS |      A |      Q| 230.25|  233.35| 228.00|  229.35|  229.35|   228.95|     2475|     54056| 12441733.00|     null|file:/content/sto...|  2021-10-04|\n",
            "|  2| 500008|AMAR RAJA BA|      A |      Q| 774.50|  774.85| 762.00|  766.15|  766.15|   765.50|     2642|     63238| 48593068.00|     null|file:/content/sto...|  2021-10-04|\n",
            "|  3| 500009|A.SARABHAI  |      X |      Q|  30.75|   31.00|  30.55|   30.65|   30.65|    30.65|      728|    145196|  4462266.00|     null|file:/content/sto...|  2021-10-04|\n",
            "|  4| 500010|HDFC        |      A |      Q|2740.00| 2769.00|2721.05| 2725.00| 2725.00|  2712.25|     6175|     83389|228666721.00|     null|file:/content/sto...|  2021-10-04|\n",
            "|  5| 500012|ANDHRA PETRO|      XT|      Q| 145.90|  145.90| 139.50|  143.05|  142.90|   141.40|     1659|    207074| 29470568.00|     null|file:/content/sto...|  2021-10-04|\n",
            "|  6| 500013|ANSAL INFRAS|      B |      Q|   8.80|    9.15|   8.80|    9.00|    9.00|     8.99|      100|     22031|   198290.00|     null|file:/content/sto...|  2021-10-04|\n",
            "|  7| 500014|UTIQUE      |      X |      Q|   2.85|    2.85|   2.70|    2.77|    2.79|     2.75|      163|     45120|   124058.00|     null|file:/content/sto...|  2021-10-04|\n",
            "|  8| 500016|ARUNAHTEL   |      XT|      Q|  13.85|   14.80|  13.85|   13.85|   13.85|    14.55|       59|      6343|    88200.00|     null|file:/content/sto...|  2021-10-04|\n",
            "|  9| 500020|BOM DYEING  |      A |      Q|  92.45|   94.80|  92.45|   93.75|   93.75|    92.45|     2304|    355846| 33322621.00|     null|file:/content/sto...|  2021-10-04|\n",
            "| 10| 500023|ASIANHOTNR  |      B |      Q|  91.70|   94.40|  89.40|   90.35|   90.65|    90.70|      111|      3929|   360779.00|     null|file:/content/sto...|  2021-10-04|\n",
            "| 11| 500027|ATUL LTD.   |      A |      Q|9801.00|10188.80|9791.00|10077.40|10077.40|  9746.00|     1486|      3050| 30367440.00|     null|file:/content/sto...|  2021-10-04|\n",
            "| 12| 500028|ATV PROJECTS|      XT|      Q|   8.50|    8.64|   8.12|    8.34|    8.34|     8.30|       52|     21069|   178328.00|     null|file:/content/sto...|  2021-10-04|\n",
            "| 13| 500029|AUTOLITE(I) |      Z |      Q|  14.90|   15.75|  14.60|   15.10|   15.01|    15.00|       48|     10140|   157760.00|     null|file:/content/sto...|  2021-10-04|\n",
            "| 14| 500031|BAJAJ ELECT.|      A |      Q|1309.45| 1340.00|1309.45| 1320.90| 1320.90|  1306.95|     1688|     12279| 16252495.00|     null|file:/content/sto...|  2021-10-04|\n",
            "| 15| 500032|BAJAJHIND   |      T |      Q|  16.60|   16.85|  16.40|   16.85|   16.85|    16.05|     1102|    479883|  8057669.00|     null|file:/content/sto...|  2021-10-04|\n",
            "| 16| 500033|FORCE MOTR  |      A |      Q|1464.25| 1494.25|1457.15| 1465.85| 1465.85|  1454.05|      653|      3102|  4580766.00|     null|file:/content/sto...|  2021-10-04|\n",
            "| 17| 500034|BAJFINANCE  |      A |      Q|7600.00| 7767.00|7554.75| 7694.20| 7694.20|  7522.05|     5378|     34746|267207626.00|     null|file:/content/sto...|  2021-10-04|\n",
            "| 18| 500038|BALRAM.CHINI|      A |      Q| 370.00|  395.10| 370.00|  392.60|  393.00|   366.20|     5448|    243062| 94221366.00|     null|file:/content/sto...|  2021-10-04|\n",
            "| 19| 500039|BANCO PROD. |      B |      Q| 191.00|  197.90| 191.00|  194.50|  194.75|   193.10|     1651|     38716|  7553732.00|     null|file:/content/sto...|  2021-10-04|\n",
            "+---+-------+------------+--------+-------+-------+--------+-------+--------+--------+---------+---------+----------+------------+---------+--------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agg"
      ],
      "metadata": {
        "id": "5EVaFjaFvOiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1  = [{'Name':'Jhon','ID':21.528,'Add':'USA'},{'Name':'Joe','ID':3.69,'Add':'USA'},{'Name':'Tina','ID':2.48,'Add':'IND'},{'Name':'Jhon','ID':22.22, 'Add':'USA'},{'Name':'Joe','ID':5.33,'Add':'INA'}]"
      ],
      "metadata": {
        "id": "aZaf2eI1ujcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = sqlContext.createDataFrame(spark.sparkContext.parallelize(data1))\n",
        "test_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDFaMCecurlN",
        "outputId": "787c7ed3-505b-428a-fe21-f9dce7ffab91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----+\n",
            "|Add|    ID|Name|\n",
            "+---+------+----+\n",
            "|USA|21.528|Jhon|\n",
            "|USA|  3.69| Joe|\n",
            "|IND|  2.48|Tina|\n",
            "|USA| 22.22|Jhon|\n",
            "|INA|  5.33| Joe|\n",
            "+---+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count\n",
        "c = test_df.groupBy('Name')\n",
        "c.count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsJ4xKF0vFl2",
        "outputId": "1cdfb60b-8750-469e-dd42-daa212d1473b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|Name|count|\n",
            "+----+-----+\n",
            "| Joe|    2|\n",
            "|Jhon|    2|\n",
            "|Tina|    1|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# agg functions\n",
        "# c.agg({'ID':'sum'}).show()\n",
        "# c.agg({'ID':'count'}).show()\n",
        "# c.agg({'ID':'avg'}).show()\n",
        "# c.agg({'ID':'max'}).show()\n",
        "# c.agg({'ID':'last'}).show()\n",
        "c.agg({'ID':'collect_list'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhbXUVFHvYKJ",
        "outputId": "45dc6fde-34af-4a90-b38e-d679ee5fc43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------------+\n",
            "|Name|collect_list(ID)|\n",
            "+----+----------------+\n",
            "| Joe|    [3.69, 5.33]|\n",
            "|Jhon| [21.528, 22.22]|\n",
            "|Tina|          [2.48]|\n",
            "+----+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plus_mean(pandas_df):\n",
        "    pandas_df = pandas_df.assign(test=pandas_df.ID.median())\n",
        "    pandas_df = pandas_df.assign(test2=pandas_df.ID.max())\n",
        "    return pandas_df\n",
        "\n",
        "test_df = test_df.withColumn('test', lit(None).cast(FloatType()))\n",
        "test_df = test_df.withColumn('test2', lit(None).cast(FloatType()))\n",
        "test_df.groupby('Name').applyInPandas(plus_mean, schema=test_df.schema).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e51-PNn3YQ2V",
        "outputId": "bac63870-7679-4e58-d4ba-a2e5163573a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----+------+-----+\n",
            "|Add|    ID|Name|  test|test2|\n",
            "+---+------+----+------+-----+\n",
            "|USA|21.528|Jhon|21.874|22.22|\n",
            "|USA| 22.22|Jhon|21.874|22.22|\n",
            "|USA|  3.69| Joe|  4.51| 5.33|\n",
            "|INA|  5.33| Joe|  4.51| 5.33|\n",
            "|IND|  2.48|Tina|  2.48| 2.48|\n",
            "+---+------+----+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.select(\"name\").distinct().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1unRH0ryxmp",
        "outputId": "f99dcb34-8172-4047-9189-a5ddc6538f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(name='Joe'), Row(name='Jhon'), Row(name='Tina')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select , withColumn\n",
        "# test_df.select(test_df.columns[0:3]).show()\n",
        "\n",
        "test_df = test_df.withColumn(\"ID\",col(\"ID\").cast(\"Integer\"))\n",
        "test_df.printSchema()\n",
        "\n",
        "test_df = test_df.withColumnRenamed(\"Add\",\"Address\")\n",
        "# Adding MULTIPLE columns.\n",
        "test_df.withColumn(\"New_Column\",lit(\"NEW\")).withColumn(\"New_Column2\",col(\"Address\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp9zK7PjzmqY",
        "outputId": "e268126e-0560-49b3-860f-e541e2b0f0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Add: string (nullable = true)\n",
            " |-- ID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- test: float (nullable = true)\n",
            "\n",
            "+-------+---+----+----+----------+-----------+\n",
            "|Address| ID|Name|test|New_Column|New_Column2|\n",
            "+-------+---+----+----+----------+-----------+\n",
            "|    USA| 21|Jhon|null|       NEW|        USA|\n",
            "|    USA|  3| Joe|null|       NEW|        USA|\n",
            "|    IND|  2|Tina|null|       NEW|        IND|\n",
            "|    USA| 22|Jhon|null|       NEW|        USA|\n",
            "|    INA|  5| Joe|null|       NEW|        INA|\n",
            "+-------+---+----+----+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### join "
      ],
      "metadata": {
        "id": "_pqAh8X_9bCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1  = [{'Name':'Jhon','ID':21.528,'Add':'USA'},{'Name':'Joe','ID':3.69,'Add':'USA'},{'Name':'Tina','ID':2.48,'Add':'IND'},{'Name':'Jhon','ID':22.22, 'Add':'USA'},{'Name':'Joe','ID':5.33,'Add':'INA'}]\n",
        "\n",
        "data2  = [{'Name':'Jhon','ID':21.528,'Add':'USA'},{'Name':'Joe','ID':3.69,'Add':'USA'},{'Name':'Tinya','ID':2.44,'Add':'IND'},{'Name':'Jhond','ID':22.2, 'Add':'USA'},{'Name':'Joe','ID':5,'Add':'IND'}]\n"
      ],
      "metadata": {
        "id": "Wn-KSlc_9ab2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df1 = sqlContext.createDataFrame(spark.sparkContext.parallelize(data1))\n",
        "test_df2 = sqlContext.createDataFrame(spark.sparkContext.parallelize(data2))"
      ],
      "metadata": {
        "id": "lLVYgT7i9l-T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "7ed5a57b-82c7-4d07-f224-8e2ca5fe90f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d38104a1f931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_df2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sqlContext' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_inner = test_df1.join(test_df2 , on=['Name']  , how = 'inner')\n",
        "df_inner.show()"
      ],
      "metadata": {
        "id": "CvaeRBfB9vea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df2.show(1, vertical=True)"
      ],
      "metadata": {
        "id": "KdLplMXRVszd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df2.take(1)"
      ],
      "metadata": {
        "id": "hpKEaZJcWH7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ranking Function"
      ],
      "metadata": {
        "id": "FZeIJVbdehlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ROW_NUMBER()\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "data1 = ((\"Bob\", \"IT\", 4500), \\\n",
        "(\"Maria\", \"IT\", 4600), \\\n",
        "(\"James\", \"IT\", 3850), \\\n",
        "(\"Maria\", \"HR\", 4500),  (\"Maria2\", \"HR\", 5200),\\\n",
        "(\"James\", \"IT\", 4500), \\\n",
        "(\"Sam\", \"HR\", 3300), \\\n",
        "(\"Jen\", \"HR\", 4450), (\"Jen2\", \"HR\", 4800),\\\n",
        "(\"Jeff\", \"Marketing\", 4500), \\\n",
        "(\"Anand\", \"Marketing\", 2000),\\\n",
        "(\"Shaid\", \"IT\", 3850) \\\n",
        ")\n",
        "col= [\"Name\", \"MBA_Stream\", \"SEM_MARKS\"]\n",
        "b = spark.createDataFrame(data1,col)\n",
        "w = Window.partitionBy(\"MBA_Stream\").orderBy(\"SEM_MARKS\")\n",
        "\n",
        "b.withColumn(\"Windowfunc_row\",row_number().over(w)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "1OVAHcq9ekB5",
        "outputId": "61d96a51-d6fe-43bd-d058-b4b5141efebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cb09fdb1c77f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ROW_NUMBER()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrow_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bob\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Maria\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"James\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3850\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Maria\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0;34m\"Maria2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"James\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Sam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Jen\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4450\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Jen2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Jeff\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Marketing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Anand\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Marketing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shaid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3850\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANK Function\n",
        "from pyspark.sql.functions import rank\n",
        "\n",
        "\n",
        "b.withColumn(\"Window_Rank\",rank().over(w)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAOZV3bRhp6K",
        "outputId": "974fb58c-bdeb-42b6-8d70-9c2ac47ce903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+---------+-----------+\n",
            "|  Name|MBA_Stream|SEM_MARKS|Window_Rank|\n",
            "+------+----------+---------+-----------+\n",
            "|   Sam|        HR|     3300|          1|\n",
            "|   Jen|        HR|     4450|          2|\n",
            "| Maria|        HR|     4500|          3|\n",
            "|  Jen2|        HR|     4800|          4|\n",
            "|Maria2|        HR|     5200|          5|\n",
            "| James|        IT|     3850|          1|\n",
            "| Shaid|        IT|     3850|          1|\n",
            "|   Bob|        IT|     4500|          3|\n",
            "| James|        IT|     4500|          3|\n",
            "| Maria|        IT|     4600|          5|\n",
            "| Anand| Marketing|     2000|          1|\n",
            "|  Jeff| Marketing|     4500|          2|\n",
            "+------+----------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ntile\n",
        "from pyspark.sql.functions import ntile\n",
        "b.withColumn(\"Window_Ntile\",ntile(2).over(w)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r-ghsOnikYx",
        "outputId": "a03fd821-1952-4473-d7b0-ac5c37d9b1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+---------+------------+\n",
            "|  Name|MBA_Stream|SEM_MARKS|Window_Ntile|\n",
            "+------+----------+---------+------------+\n",
            "|   Sam|        HR|     3300|           1|\n",
            "|   Jen|        HR|     4450|           1|\n",
            "| Maria|        HR|     4500|           1|\n",
            "|  Jen2|        HR|     4800|           2|\n",
            "|Maria2|        HR|     5200|           2|\n",
            "| James|        IT|     3850|           1|\n",
            "| Shaid|        IT|     3850|           1|\n",
            "|   Bob|        IT|     4500|           1|\n",
            "| James|        IT|     4500|           2|\n",
            "| Maria|        IT|     4600|           2|\n",
            "| Anand| Marketing|     2000|           1|\n",
            "|  Jeff| Marketing|     4500|           2|\n",
            "+------+----------+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SubString "
      ],
      "metadata": {
        "id": "D6J3_DJoFs9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit, concat\n",
        "\n",
        "a= spark.createDataFrame([\"SAM\",\"JOHN\",\"AND\",\"ROBIN\",\"ANAND\"], \"string\").toDF(\"Name\")\n",
        "# b=a.withColumn(\"Sub_Name\",a.Name.substr(1,5)).show()\n",
        "b = a.withColumn(\"Concated_Value\", concat(a.Name.substr(-5,5),lit(\"--\"),a.Name.substr(1,2))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H8TRwyLF5dK",
        "outputId": "141146b4-0e07-415b-b17e-c0d1f076d32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------+\n",
            "| Name|Concated_Value|\n",
            "+-----+--------------+\n",
            "|  SAM|       SAM--SA|\n",
            "| JOHN|      JOHN--JO|\n",
            "|  AND|       AND--AN|\n",
            "|ROBIN|     ROBIN--RO|\n",
            "|ANAND|     ANAND--AN|\n",
            "+-----+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PySpark read parquet"
      ],
      "metadata": {
        "id": "D8VgwlKCKxQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dir_path = os.path.dirname(os.path.realpath('spark_detail.ipynb'))\n",
        "dir_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JkOawkVNLLsu",
        "outputId": "62ff9bb7-64aa-4233-bc5a-a88b8a7af099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = ((\"Bob\", \"IT\", 4500), \\\n",
        "(\"Maria\", \"IT\", 4600),  \\\n",
        "(\"James\", \"IT\", 3850),   \\\n",
        "(\"Maria\", \"HR\", 4500),  \\\n",
        "(\"James\", \"IT\", 4500),    \\\n",
        "(\"Sam\", \"HR\", 3300),  \\\n",
        "(\"Jen\", \"HR\", 3900),    \\\n",
        "(\"Jeff\", \"Marketing\", 4500), \\\n",
        "(\"Anand\", \"Marketing\", 2000),\\\n",
        "(\"Shaid\", \"IT\", 3850) \\\n",
        ")\n",
        "col= [\"Name\", \"MBA_Stream\", \"SEM_MARKS\"]\n",
        "b = spark.createDataFrame(data1,col)\n",
        "b.printSchema()\n",
        "\n",
        "b.write.parquet(dir_path + \"/test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFftbqRgKzM2",
        "outputId": "30a7b640-3383-422d-b56f-b582290092cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- MBA_Stream: string (nullable = true)\n",
            " |-- SEM_MARKS: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.parquet(dir_path + \"/test\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXmbpYN6Md0Y",
        "outputId": "e05d7246-90bf-4f35-fbf7-89efe2f9998e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+---------+\n",
            "| Name|MBA_Stream|SEM_MARKS|\n",
            "+-----+----------+---------+\n",
            "|  Bob|        IT|     4500|\n",
            "|Maria|        IT|     4600|\n",
            "|James|        IT|     3850|\n",
            "|Maria|        HR|     4500|\n",
            "|James|        IT|     4500|\n",
            "+-----+----------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PYSPARK COLUMN TO LIST"
      ],
      "metadata": {
        "id": "UEGdhrvugDRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = [{'Name':'Jhon','ID':21.528,'Add':'USA'},{'Name':'Joe','ID':3.69,'Add':'USA'},{'Name':'Tina','ID':2.48,'Add':'IND'},{'Name':'Jhon','ID':22.22, 'Add':'USA'},{'Name':'Joe','ID':5.33,'Add':'INA'}]\n",
        "\n",
        "a = spark.sparkContext.parallelize(data1)\n",
        "b = spark.createDataFrame(a)\n"
      ],
      "metadata": {
        "id": "fIJxn8eJgGAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using lambda\n",
        "\n",
        "b.rdd.map(lambda x: x[2]).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpDkWhQ6gpO2",
        "outputId": "db2bbfdb-6d73-4efd-e7a9-78b64a281105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jhon', 'Joe', 'Tina', 'Jhon', 'Joe']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using flatMap\n",
        "\n",
        "b.select(b.Name).rdd.flatMap(lambda x: x).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPuCvObtgvWG",
        "outputId": "f1d1cf54-1126-4c43-e5ac-67f822752ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jhon', 'Joe', 'Tina', 'Jhon', 'Joe']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Structtype"
      ],
      "metadata": {
        "id": "lwq0b4-zi_7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nes_Sch = StructType(\n",
        "    [\n",
        "        StructField(\n",
        "            \"Name\",\n",
        "            StructType(\n",
        "                [\n",
        "                    StructField(\"f_name\", StringType(), True),\n",
        "                    StructField(\"l_name\", StringType(), True),\n",
        "                ]\n",
        "            ),\n",
        "        ),\n",
        "        StructField(\"ID\", StringType(), True),\n",
        "        StructField(\"Add\", StringType(), True),\n",
        "    ]\n",
        ")\n",
        "data1 = [((\"John\",\"cena\"),\"123\",\"UK\"),((\"Singh\",\"dd\"),\"234\",\"IND\")] \n",
        "b = spark.createDataFrame(data1,nes_Sch)\n",
        "b.show()\n",
        "b.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oxfyny6i_E8",
        "outputId": "cecdefe5-18a6-4334-9bd8-8ac84f18a057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---+---+\n",
            "|        Name| ID|Add|\n",
            "+------------+---+---+\n",
            "|{John, cena}|123| UK|\n",
            "| {Singh, dd}|234|IND|\n",
            "+------------+---+---+\n",
            "\n",
            "root\n",
            " |-- Name: struct (nullable = true)\n",
            " |    |-- f_name: string (nullable = true)\n",
            " |    |-- l_name: string (nullable = true)\n",
            " |-- ID: string (nullable = true)\n",
            " |-- Add: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b[['Name.f_name']].show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4YXh6Avjqrt",
        "outputId": "0d15ac19-5ce1-47f5-a378-ff985f0e0d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|f_name|\n",
            "+------+\n",
            "|  John|\n",
            "| Singh|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PYSPARK EXPLODE"
      ],
      "metadata": {
        "id": "wsglrrjxpm8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "data1  = [(\"Jhon\",[[\"USA\",\"MX\",\"USW\",\"UK\"],[\"23\",\"34\",\"56\"]]),(\"Joe\",[[\"IND\",\"AF\",\"YR\",\"QW\"],[\"22\",\"35\",\"76\"]]),(\"Juhi\",[[\"USA\",\"MX\",\"USW\",\"UK\"],[\"13\",\"64\",\"59\"]]),(\"Jhony\",[[\"USSR\",\"MXR\",\"USA\",\"UK\"],[\"22\",\"44\",\"76\"]])]\n",
        "\n",
        "\n",
        "data_frame = spark.createDataFrame(data=data1, schema = ['name','subjectandID'])"
      ],
      "metadata": {
        "id": "Yyy5cYWFppAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.printSchema()\n",
        "data_frame.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkJmLnMQq2l3",
        "outputId": "6aa8a53c-9598-4038-9986-ee0981b63747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- subjectandID: array (nullable = true)\n",
            " |    |-- element: array (containsNull = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-----+------------------------------------+\n",
            "|name |subjectandID                        |\n",
            "+-----+------------------------------------+\n",
            "|Jhon |[[USA, MX, USW, UK], [23, 34, 56]]  |\n",
            "|Joe  |[[IND, AF, YR, QW], [22, 35, 76]]   |\n",
            "|Juhi |[[USA, MX, USW, UK], [13, 64, 59]]  |\n",
            "|Jhony|[[USSR, MXR, USA, UK], [22, 44, 76]]|\n",
            "+-----+------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = data_frame.select(data_frame.name,explode(data_frame.subjectandID))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcyvWDtzq3_K",
        "outputId": "953e73ad-2ca1-4117-8fd3-1efc4273f7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- col: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-----+--------------------+\n",
            "| name|                 col|\n",
            "+-----+--------------------+\n",
            "| Jhon|  [USA, MX, USW, UK]|\n",
            "| Jhon|        [23, 34, 56]|\n",
            "|  Joe|   [IND, AF, YR, QW]|\n",
            "|  Joe|        [22, 35, 76]|\n",
            "| Juhi|  [USA, MX, USW, UK]|\n",
            "| Juhi|        [13, 64, 59]|\n",
            "|Jhony|[USSR, MXR, USA, UK]|\n",
            "|Jhony|        [22, 44, 76]|\n",
            "+-----+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "def get_date(value):\n",
        "  f_name, _ = os.path.splitext(os.path.basename(value))\n",
        "  col_date = datetime. strptime(f_name[-6:], '%d%m%y').date()\n",
        "  return str(col_date)\n",
        "\n",
        "print(get_date('file:/content/stocks/EQ041021.CSV'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO3Lbttz7Jw1",
        "outputId": "0872e550-98e3-45e1-88aa-3a00ff286abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-04\n"
          ]
        }
      ]
    }
  ]
}